---
title: 'Sensitivity analysis: MPA pct rasters'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(sf)
library(fasterize)

source('https://raw.githubusercontent.com/oharac/src/master/R/common.R')  ###
  ### includes library(tidyverse); library(stringr); dir_M points to ohi directory

dir_git <- '~/github/spp_risk_dists'

### goal specific folders and info
dir_spatial <- file.path(dir_git, '_spatial')
dir_o_anx   <- file.path(dir_O, 'git-annex/spp_risk_dists')
dir_wdpa <- file.path(dir_o_anx, 'wdpa')
dir_sa   <- file.path(dir_wdpa, 'sensitivity_analysis')
# ### provenance tracking
# library(provRmd); prov_setup()

source('common_fxns.R')
```

# Summary

This sensitivity analysis is designed to answer reviewer questions on potential of rasterization to underrepresent small MPAs.

# Data Sources

### WDPA

# Methods

1. Examine the WDPA dataset to identify the number and proportion of small MPAs and their contribution to the global MPA estate.  
    a. For this sensitivity analysis, we will focus on the no-take MPAs discussed in the manuscript rather than worrying about categories III or higher - the technical issues are identical, and focusing on the smaller subset keeps the analysis significantly lighter computationally.
    b. Similarly, we will not worry about the year raster - just the protection raster.
2. Focusing on these small MPAs (less than some threshold of area, say 100 km^2), compare the total area as determined by 
    a. polygon (probably need to union the set to avoid overlap issues)
    b. rasters at 1 km resolution, and maybe 2 km, 5km, and 10 km.  Is .5 km reasonable?
3. Depending on the results of 2 (and the speed by which polygon area can be calculated without overlaps), perform the same test incorporating all MPAs.

## Explore WDPA MPA areas

```{r create wdpa marine shapefile}

mpa_poly_file    <- file.path(dir_sa, 'mpa_by_cat_jun2018.shp')
notake_poly_file <- file.path(dir_sa, 'mpa_notake_jun2018.shp')

if(!file.exists(mpa_poly_file)) {

  wdpa_poly_file <- file.path(dir_wdpa, 
                              'wdpa_jun2018/WDPA_June2018-shapefile-polygons.shp')
  wdpa_poly <- sf::read_sf(wdpa_poly_file)

  # wdpa_poly$IUCN_CAT %>% unique()
  iucn_cats <- c('Ia'  = 1,
                 'Ib'  = 1,
                 'II'  = 2,
                 'III' = 3,
                 'IV'  = 4,
                 'V'   = 5,
                 'VI'  = 6)
  
  mpa_poly <- wdpa_poly %>%
    filter(MARINE > 0 | GIS_M_AREA > 0) %>%
    filter(STATUS %in% c('Designated', 'Adopted', 'Established')) %>%
      ### no paper parks!
    filter(!str_detect(tolower(MANG_PLAN), 'non-mpa')) %>%
      ### omit non-MPA fisheries or species management plans!
    mutate(NO_TAKE = ifelse(WDPAID == 309888, TRUE, NO_TAKE),
             ### patch PIPA to be no take - currently "not reported"
           no_take = (NO_TAKE == 'All') | (NO_TAKE == 'Part' & NO_TK_AREA > 0.75 * GIS_M_AREA),
             ### if NO_TK_AREA is 75% or more of GIS area, count it...
           cat = iucn_cats[IUCN_CAT],
           cat = ifelse(no_take & !cat %in% 1:2, -1, cat), ### use -1 as a "no take" flag
           cat = ifelse(is.na(cat), 8, cat), ### use 8 as an "other protected" flag
           id  = 1:n()) %>%           ### set a unique number ID for each polygon
    mutate(area_km2 = st_area(geometry) / 1e6 %>% as.numeric()) %>%
    arrange(cat) %>%
    st_transform(crs = gp_proj4) %>%
    select(id, cat, area_km2, NAME, DESIG = DESIG_ENG, IUCN_CAT, 
           MARINE, no_take, stat_yr = STATUS_YR, ISO3,
           geometry) %>%
    clean_df_names()
  
  write_sf(mpa_poly, mpa_poly_file)
  
  ### notake_poly will have different identifiers, and in order of area
  notake_poly <- mpa_poly %>%
    filter(cat <= 2) %>%
    arrange(area_km2) %>%
    mutate(id = 1:n())
  write_sf(notake_poly, notake_poly_file)
  
}
  
```

```{r}

if(!exists('mpa_poly')) mpa_poly <- read_sf(mpa_poly_file)

mpa_poly_df <- mpa_poly %>%
  as.data.frame() %>%
  select(-geometry) %>%
  arrange(area_km2) %>%
  mutate(cum_area = cumsum(area_km2))

# quantile(mpa_poly_df$area_km2, seq(.1, 1, .1))
#          10%          20%          30%          40%          50% 
# 6.937578e-02 2.823776e-01 8.466203e-01 2.181692e+00 4.947681e+00 
#          60%          70%          80%          90%         100% 
# 1.144168e+01 2.986043e+01 9.505311e+01 4.404398e+02 1.969102e+06
#          
# quantile(mpa_poly_df$cum_area, seq(.1, 1, .1))
#          10%          20%          30%          40%          50%          60% 
# 4.904247e+01 3.314999e+02 1.242052e+03 3.818108e+03 9.905974e+03 2.363168e+04 
#          70%          80%          90%         100% 
# 5.771246e+04 1.572418e+05 5.418549e+05 2.993869e+07

ggplot(mpa_poly_df %>% 
         filter(id %% 10 == 0), ### thin the data set a bit to see if those lines go away... doesn't affect cum sum
       aes(x = area_km2, y = cum_area)) +
  ggtheme_plot() +
  geom_area(fill = 'grey30', alpha = .6) +
  geom_vline(xintercept = 100, color = 'red') +
  scale_x_log10(limits = c(.1, NA), breaks = c(.1, 1, 10, 100, 1000, 10000))

mpa_poly_small <- mpa_poly_df %>%
  mutate(size = case_when(area_km2 < 1 ~ '< 1 km^2',
                          area_km2 < 100 ~ '< 100 km^2', 
                          area_km2 < 1000 ~ '< 1000 km^2', 
                          TRUE ~ '>= 1000 km^2')) %>%
  group_by(size) %>%
  summarize(a_tot = sum(area_km2),
            n_mpa = n()) %>%
  mutate(pct_tot = a_tot / sum(a_tot) * 100)

knitr::kable(mpa_poly_small)

```

The shows that cumulatively, there are more than 14,000 MPAs smaller than 100 km^2^, with a total area of 0.55% of all protected areas.  There are 3500 MPAs larger than 100 km^2^, that include 99.45% of all protected areas.  So by total area, the small MPAs are rather negligible in terms of coverage (though they may be protecting very important small habitats!)

This covers all MPA classes.  Let's examine those considered for the main analysis, i.e. no take MPAs.

``` {r}

marine_notake_df <- mpa_poly_df %>%
  filter(cat <= 2) %>%
  arrange(area_km2) %>%
  mutate(cum_area = cumsum(area_km2))

# quantile(marine_notake_df$area_km2, seq(.1, 1, .1))
#          10%          20%          30%          40%          50% 
# 5.890078e-02 1.811871e-01 4.283858e-01 1.114906e+00 2.884445e+00 
#          60%          70%          80%          90%         100% 
# 8.285086e+00 2.773088e+01 1.084514e+02 6.501285e+02 1.555860e+06 
# quantile(marine_notake_df$cum_area, seq(.1, 1, .1))
#          10%          20%          30%          40%          50% 
# 9.053093e+00 4.666741e+01 1.442420e+02 3.872801e+02 9.996083e+02 
#          60%          70%          80%          90%         100% 
# 2.722616e+03 7.973807e+03 2.701260e+04 1.253577e+05 1.125946e+07 
         
ggplot(marine_notake_df, aes(x = area_km2, y = cum_area)) +
  ggtheme_plot() +
  geom_area(fill = 'grey30', alpha = .6) +
  geom_vline(xintercept = 100, color = 'red') +
  scale_x_log10(limits = c(0.1, NA), breaks = c(.1, 1, 10, 100, 1000, 10000))

marine_notake_small <- marine_notake_df %>%
  mutate(size = case_when(area_km2 < 1 ~ '< 1 km^2',
                          area_km2 < 100 ~ '< 100 km^2', 
                          area_km2 < 1000 ~ '< 1000 km^2', 
                          TRUE ~ '>= 1000 km^2')) %>%
  group_by(size) %>%
  summarize(a_tot = sum(area_km2),
            n_mpa = n()) %>%
  mutate(pct_tot = a_tot / sum(a_tot) * 100)

knitr::kable(marine_notake_small)

```

The pattern is even more pronounced for no-take MPAs than for the entire collection of MPAs regardless of category: small no-take MPAs contribute a tiny amount to the global MPA estate.

However, our analysis doesn't simply drop these small MPAs.  Next let's examine how well the rasterization process accounts for MPAs smaller than 100 km^2^.

## Explore effects of rasterization

### Create no-take maps at GP 1 km^2 resolution

Occasionally within the WDPA dataset, multiple protected area polygons overlap, for example Channel Islands National Marine Sanctuary and the MPAs within it.  Rasterization solves the problem of overlapping MPAs by simply choosing one value for each cell within the overlapping areas.  However, this makes it more challenging to compare raster area to polygon area.  

To get around this, for this sensitivity analysis, we will simply drop the larger of overlapping protected areas (noted by having the larger id, since in order of size).  While this means the sensitivity analysis is not acting on exactly the same dataset as in the full analysis, it is acting on a very representative subset.

``` {r create_nonoverlapping_poly_set}

notake_poly <- read_sf(notake_poly_file)

notake_intsx <- st_intersects(notake_poly) %>%
  lapply(as.integer) ### ditch the sgbp class 

intsx_drop <- data.frame(id = 1:length(notake_intsx)) %>%
  mutate(intsx = notake_intsx) %>%
  unnest(intsx) %>%
  filter(intsx > id) %>%
  .$intsx %>% unique()
### 468 unique polygons that overlap smaller polygons.
  
notake_no_intsx <- notake_poly %>%
  filter(!id %in% intsx_drop)
### 2862 polygons with no intersections:
# check <- st_intersects(notake_no_intsx) %>%
#   sapply(length) %>% all(. == 1)

ocean_1km_file  <- file.path(dir_o_anx, 'spatial', 'ocean_1km.tif')

rast_ocean_1km  <- raster(ocean_1km_file)

notake_1km_no_intsx_file <- file.path(dir_sa, 'notake_no_intsx_rast_by_id.tif')
notake_1km_no_intsx_ocean_file <- file.path(dir_sa, 'notake_no_intsx_ocean_rast_by_id.tif')
notake_1km_file       <- file.path(dir_sa, 'notake_rast_by_id.tif')
notake_1km_ocean_file <- file.path(dir_sa, 'notake_ocean_rast_by_id.tif')

if(!all(file.exists(notake_1km_file, notake_1km_ocean_file, 
                    notake_1km_no_intsx_file, notake_1km_no_intsx_ocean_file))) {

  ### rasterize notake areas to 1 km global raster
  notake_rast_1km <- fasterize(sf = notake_poly, 
                               raster = rast_ocean_1km,
                               field  = 'id', 
                               fun    = 'min')
  notake_no_intsx_rast_1km <- fasterize(sf = notake_no_intsx, 
                               raster = rast_ocean_1km,
                               field  = 'id', 
                               fun    = 'min')

  ### clip out any non-ocean area
  values(rast_ocean_1km)[values(rast_ocean_1km) < .005] <- NA
  notake_ocean_rast_1km <- mask(notake_rast_1km, rast_ocean_1km)
  notake_no_intsx_ocean_rast_1km <- mask(notake_no_intsx_rast_1km, rast_ocean_1km)

  ### Save the full rasters (incl land areas)
  writeRaster(notake_rast_1km, notake_1km_file, 
              progress = 'text',
              overwrite = TRUE)
  writeRaster(notake_no_intsx_rast_1km, notake_1km_no_intsx_file, 
              progress = 'text',
              overwrite = TRUE)
  ### Save the ocean-clipped rasters
  writeRaster(notake_ocean_rast_1km, notake_1km_ocean_file, 
              progress = 'text',
              overwrite = TRUE)
  writeRaster(notake_no_intsx_ocean_rast_1km, notake_1km_no_intsx_ocean_file, 
              progress = 'text',
              overwrite = TRUE)
}
  
```

Compare number of cells represented for each MPA ID to the calculated polygon area.  We would expect that the best matches would come from looking only at non-intersecting MPAs, prior to clipping for ocean cells; intersecting MPAs will drop cells from one park or the other, while some MPAs also include land area that will be dropped when clipping to only ocean cells.  For this sensitivity analysis, we are interested in the effects of the rasterization process, so we can safely set aside the question of intersecting parks and parks that encompass some terrestrial area.

We would also expect that the larger the park, the smaller the proportional difference between raster-calculated area and polygon-calculated area, as the differences will occur at the polygon boundaries.  The area will increase more quickly (as squared) than the perimeter (as linear).

```{r count areas and overlaps}

notake_rast_1km <- raster(notake_1km_file)
notake_no_intsx_rast_1km <- raster(notake_1km_no_intsx_file)
notake_ocean_rast_1km <- raster(notake_1km_ocean_file)
notake_no_intsx_ocean_rast_1km <- raster(notake_1km_no_intsx_ocean_file)

get_rast_areas <- function(rast, code) {
  table(values(rast)) %>%
    data.frame() %>%
    rename(id = Var1, cells = Freq) %>%
    mutate(id = as.integer(as.character(id)), ### argh, factors
           code = code)
}
  
compare_file <- file.path(dir_sa, 'area_compare.csv')
### unlink(compare_file)
if(!file.exists(compare_file)) {

  
  areas_all   <- get_rast_areas(notake_rast_1km, 
                                code = 'all')
  areas_ocean <- get_rast_areas(notake_ocean_rast_1km, 
                                code = 'ocean')
  areas_all_no_intsx   <- get_rast_areas(notake_no_intsx_rast_1km, 
                                         code = 'all_no_intsx')
  areas_ocean_no_intsx <- get_rast_areas(notake_no_intsx_ocean_rast_1km, 
                                         code = 'ocean_no_intsx')
  
  rast_areas_df <- bind_rows(areas_all, areas_ocean, 
                             areas_all_no_intsx, areas_ocean_no_intsx)
  
  notake_areas_df <- notake_no_intsx %>%
    as.data.frame() %>%
    select(id, area_km2) %>%
    left_join(rast_areas_df, by = 'id') %>%
    mutate(cells   = ifelse(is.na(cells), 0, cells),
           diff = area_km2 - cells,
           pct_diff = 100 * diff / area_km2)
  
  write_csv(notake_areas_df, compare_file)
}

notake_areas_df <- read_csv(compare_file)

abs_area_diffs_df <- notake_areas_df %>%
  filter(code == 'all_no_intsx' | is.na(code)) %>%
  mutate(size_class = case_when(area_km2 < .001 ~ '< .001',
                                area_km2 < .01  ~ '< .01',
                                area_km2 < .1   ~ '< .1',
                                area_km2 < 1    ~ '< 1',
                                area_km2 < 3    ~ '< 3',
                                area_km2 < 10   ~ '< 10',
                                TRUE            ~ '>= 10'),
         size_class = fct_inorder(size_class)) %>%
  group_by(size_class) %>%
  summarize(area_in_class  = sum(area_km2),
            cells_in_class = sum(cells, na.rm = TRUE),
            abs_area_diff  = sum(abs(area_km2 - cells))) %>%
  mutate(cum_abs_area_diff = cumsum(abs_area_diff),
         cum_pct_abs_area_diff = 100 * cum_abs_area_diff / sum(area_in_class))

real_area_diffs_df <- notake_areas_df %>%
  filter(code == 'all_no_intsx' | is.na(code)) %>%
  mutate(size_class = case_when(area_km2 < .001 ~ '< .001',
                                area_km2 < .01  ~ '< .01',
                                area_km2 < .1   ~ '< .1',
                                area_km2 < 1    ~ '< 1',
                                area_km2 < 3    ~ '< 3',
                                area_km2 < 10   ~ '< 10',
                                TRUE            ~ '>= 10'),
         size_class = fct_inorder(size_class)) %>%
  group_by(size_class) %>%
  summarize(area_in_class  = sum(area_km2),
            cells_in_class = sum(cells, na.rm = TRUE),
            sum_area_diff  = sum(area_km2 - cells)) %>%
  mutate(cum_area_diff = cumsum(sum_area_diff),
         cum_pct_area_diff = 100 * cum_area_diff / sum(area_in_class))
  
knitr::kable(abs_area_diffs_df)
knitr::kable(real_area_diffs_df)

ggplot(notake_areas_df %>% 
         filter(code == 'all_no_intsx'),
         # filter(!is.na(code)), 
       aes(x = area_km2, y = pct_diff)) +
  ggtheme_plot() +
  geom_point() +
  scale_x_log10() # +
  # facet_wrap(~ code, scales = 'free_y')

ggplot(notake_areas_df %>% 
         filter(code == 'all_no_intsx') %>%
         # filter(!is.na(code)) %>%
         filter(area_km2 > .1), 
       aes(x = area_km2, y = pct_diff)) +
  ggtheme_plot() +
  geom_point() +
  scale_x_log10() +
  ylim(c(-250, NA))# +
  # facet_wrap(~ code, scales = 'free_y')

dropped_areas <- notake_areas_df %>%
  filter(is.na(code) | code == 'all_no_intsx') %>%
  mutate(dropped = pct_diff == 100,
         size_class = case_when(area_km2 < .001 ~ '< .001',
                                area_km2 < .01  ~ '< .01',
                                area_km2 < .1   ~ '< .1',
                                area_km2 < 1    ~ '< 1',
                                area_km2 < 3    ~ '< 3',
                                area_km2 < 10   ~ '< 10',
                                TRUE            ~ '>= 10'),
         size_class = fct_inorder(size_class)) %>%
  group_by(size_class) %>%
  summarize(n_in_class = n(),
            n_dropped = sum(dropped),
            area_in_class = sum(area_km2),
            area_dropped  = sum(area_km2 * dropped),
            pct_dropped = n_dropped / n(),
            pct_area_dropped = area_dropped / area_in_class) %>%
  mutate(cum_area_dropped = cumsum(area_dropped),
         cum_pct_area_dropped = cum_area_dropped / sum(area_in_class))
```

### Area difference by size class

Difference in area calculated as $\sum(A_{polygon} - A_{raster})$.  Negative differences and positive differences may offset each other; the aggregate is the real total difference in MPA coverage.

`r knitr::kable(real_area_diffs_df)`

### Absolute area difference by size class

Difference in area calculated as $\sum|A_{polygon} - A_{raster}|$.  Negative differences and positive differences are both penalized, resulting in a more conservative estimate of the differences.

`r knitr::kable(abs_area_diffs_df)`

## Explore effect of calculating to analysis raster resolution

To calculate protected area at the analysis scale, i.e. 100 km^2^ cells, we count the proportion of protected cells at 1 km^2^ that fall within each 100 km^2^ cell, then divide by 100.  We can then compare the sum of all cell areas to the total polygon area.  The results should be identical to the calculations using 1 km^2^ cells.

```{r}

notake_areas_df <- read_csv(compare_file)
id_to_class <- notake_areas_df %>%
  as.data.frame() %>% ### not working with raster::subs()
  filter(code == 'all_no_intsx' | is.na(code)) %>%
  mutate(size_class = case_when(area_km2 < .001 ~ '< .001',
                                area_km2 < .01  ~ '< .01',
                                area_km2 < .1   ~ '< .1',
                                area_km2 < 1    ~ '< 1',
                                area_km2 < 3    ~ '< 3',
                                area_km2 < 10   ~ '< 10',
                                TRUE            ~ '>= 10'),
         size_class = fct_inorder(size_class),
         size_code  = as.integer(size_class))

size_class_100km2_file <- file.path(dir_sa, 'prot_by_size_class_100km2.csv')

if(!file.exists(size_class_100km2_file)) {
  
  notake_rast <- raster(notake_1km_no_intsx_file)
  cell_id_1km  <- raster(file.path(dir_o_anx, 'spatial/cell_id_1km.tif'))

  ### Break into smaller chunks for parallelization
  n_chunks <- 30
  
  crosstab_chunk <- function(rast1, rast2, chunk, n_chunks) {
    ### chunk <- 30
    chunk_size <- ceiling(ncol(rast1) / n_chunks)
    left_bound <- (chunk - 1) * chunk_size + 1
    right_bound <- min(left_bound + chunk_size, ncol(rast1))
    
    chunk_ext <- extent(rast1, 1, nrow(rast1), left_bound, right_bound)
    message('Processing ', chunk, ': ', paste0(as.character(round(chunk_ext)), collapse = ', '))
    mpa_chunk     <- crop(rast1, chunk_ext) %>%
      subs(y = id_to_class, 
           by = 'id', which = 'size_code')
    cell_id_chunk <- crop(rast2, chunk_ext)
    
    mpa_cells <- crosstab(mpa_chunk, cell_id_chunk, 
                          progress = 'text',
                          long = TRUE) %>%
      setNames(c('size_code', 'cell_id', 'n_prot')) %>%
      mutate(size_code = as.integer(as.character(size_code)),
             cell_id   = as.integer(as.character(cell_id)))
        ### wdpa_category and cell_id are crosstabbed as factors - first
        ### convert to character (to unfactorize it) then to integer.  Otherwise
        ### you end up with factor index, not actual cell ID or category.
    
    if(nrow(mpa_cells) == 0) mpa_cells <- data.frame(error = 'zero length result')
    
    return(mpa_cells)
  }

  ### Use the function in an mclapply call
  system.time({
    mpa_cells_list <- parallel::mclapply(1:n_chunks, mc.cores = 5,
      FUN = function(x) crosstab_chunk(notake_rast, 
                                       cell_id_1km, 
                                       chunk = x, n_chunks))
  #     user   system  elapsed 
  # 1184.324  814.096  208.082 
  })
  
  mpa_cells_df <- bind_rows(mpa_cells_list)
  
  size_class_area_df <- id_to_class %>%
    group_by(size_class, size_code) %>%
    summarize(area_km2 = sum(area_km2),
              cells = sum(cells))
  
  mpa_area_df <- mpa_cells_df %>%
    full_join(size_class_area_df, by = c('size_code')) %>%
    filter(!is.na(size_class)) %>%
    mutate(prot_area_km2 = n_prot, ### count of cells in 1 km^2 raster
           mpa_pct = prot_area_km2 / 100) %>%
    select(size_class, cell_id, mpa_pct, prot_area_km2)

  write_csv(mpa_area_df, size_class_100km2_file)
  
}

mpa_area_df <- read_csv(size_class_100km2_file)

poly_area_summary <- id_to_class %>%
  group_by(size_class) %>%
  summarize(poly_area_in_class = sum(area_km2))

rast_area_summary <- mpa_area_df %>%
  group_by(size_class) %>%
  summarize(rast_area_in_class = sum(prot_area_km2, na.rm = TRUE)) %>%
  left_join(poly_area_summary, by = 'size_class') %>%
  mutate(size_class = factor(size_class, levels = levels(poly_area_summary$size_class))) %>%
  arrange(size_class) %>%
  mutate(cum_area_rast = cumsum(rast_area_in_class),
         cum_area_poly = cumsum(poly_area_in_class),
         pct_diff = 100 * (cum_area_poly - cum_area_rast) / cum_area_poly)

knitr::kable(rast_area_summary)
```



```{r}
old_csv <- read_csv(file.path(dir_spatial, 'wdpa_mpa_area_orig.csv')) %>%
  rename(mpa_pct_orig = mpa_pct, prot_area_km2_orig = prot_area_km2)
new_csv <- read_csv(file.path(dir_spatial, 'wdpa_mpa_area.csv'))

compare <- new_csv %>%
  full_join(old_csv, by = c('cell_id', 'wdpa_category')) %>%
  mutate(mpa_pct = round(mpa_pct, 3),
         mpa_pct_orig = round(mpa_pct_orig, 3),
         match = (mpa_pct == mpa_pct_orig) & (prot_area_km2 == prot_area_km2_orig)) %>%
  filter(!match)

```

